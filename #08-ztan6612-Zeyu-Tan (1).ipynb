{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‘ QwZT7T-TXT0 ’, 579119 ,‘ GB ’\n",
      "‘ QwZT7T-TXT0 ’, 478100 ,‘ US ’\n",
      "‘ BEePFpC9qG8 ’, 365862 ,‘ DE ’\n",
      "‘ RmZ3DPJQo2k ’, 334390 ,‘ KR ’\n",
      "‘ q8v9MvManKE ’, 299044 ,‘ IN ’\n",
      "‘ pOHQdIDds6s ’, 160365 ,‘ CA ’\n",
      "‘ ZGEoqPpJQLE ’, 151913 ,‘ RU ’\n",
      "‘ 84LBjXaeKk4 ’, 134836 ,‘ FR ’\n",
      "‘ 84LBjXaeKk4 ’, 134834 ,‘ DE ’\n",
      "‘ 84LBjXaeKk4 ’, 121240 ,‘ RU ’\n"
     ]
    }
   ],
   "source": [
    "# workload 1\n",
    "#close previous sc and open a new one\n",
    "sc.stop()\n",
    "sc = SparkContext(appName = \"wK1\")\n",
    "# File -> video_id,trending_date,category,views,likes,dislikes,country\n",
    "file = sc.textFile(\"AllVideos.csv\")\n",
    "#define a function to get attributions\n",
    "def getAtrs(row):\n",
    "    row_list = row.split(\",\")\n",
    "    date = row_list[1].split(\".\")\n",
    "    seq = (date[0],date[2],date[1])\n",
    "    row_list[1] = \".\".join(seq)\n",
    "    return ((row_list[0],row_list[6]),(row_list[1],int(row_list[4]),int(row_list[5])))\n",
    "\n",
    "#define a function to calculate the trending videos of dislike and like\n",
    "def trend(row):\n",
    "    key, value = row\n",
    "    count_dislike = value[-1][2] - value[0][2]\n",
    "    count_like = value[-1][1] - value[0][1]\n",
    "    count = count_dislike - count_like\n",
    "    return key, count\n",
    "\n",
    "rdd1 = file.map(getAtrs)\n",
    "rdd2 = rdd1.groupByKey().mapValues(list).filter(lambda x:len(x[1]) > 1)\n",
    "rdd3 = rdd2.map(trend).sortBy(lambda x: x[1], False).take(10)\n",
    "for row in rdd3:\n",
    "    print(\"‘\",row[0][0],\"’,\",row[1],\",‘\",row[0][1],\"’\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Trailers', 1.0)\n",
      "('Autos & Vehicles', 1.0190448285965426)\n",
      "('News & Politics', 1.0527098256521152)\n",
      "('Nonprofits & Activism', 1.057344064386318)\n",
      "('Education', 1.0628976994615762)\n",
      "('People & Blogs', 1.063884131133748)\n",
      "('Pets & Animals', 1.0703560703560704)\n",
      "('Howto & Style', 1.0875230863944183)\n",
      "('Travel & Events', 1.0929411764705883)\n",
      "('Gaming', 1.09443748882132)\n",
      "('Sports', 1.1421507122296848)\n",
      "('Entertainment', 1.1446024282935856)\n",
      "('Science & Technology', 1.1626835588828102)\n",
      "('Film & Animation', 1.1677314564158094)\n",
      "('Comedy', 1.2142258635136394)\n",
      "('Movies', 1.25)\n",
      "('Music', 1.3105183216252136)\n",
      "('Shows', 1.555045871559633)\n"
     ]
    }
   ],
   "source": [
    "# workload 2\n",
    "sc.stop()\n",
    "sc1.stop()\n",
    "sc1 = SparkContext(appName=\"wK2\")\n",
    "file1 = sc1.textFile(\"AllVideos.csv\")\n",
    "# File -> video_id,trending_date,category,views,likes,dislikes,country\n",
    "# video_id, category, country are what we need\n",
    "\n",
    "# define a function to get the attributes we need\n",
    "def getAtr1(row):\n",
    "    row_list = row.split(\",\")\n",
    "    return ((row_list[0],row_list[2]),row_list[6])\n",
    "\n",
    "#the country will occur mutiple times, we need unique value for contry\n",
    "def getUniqueValue(row):\n",
    "    key = row[0]\n",
    "    row = list(row[1])\n",
    "    return key[1],len(np.unique(row))\n",
    "\n",
    "\n",
    "r1 = file1.map(getAtr1).groupByKey().map(getUniqueValue)\n",
    "r2 = r1.groupByKey().mapValues(list).mapValues(lambda x:np.average(x)).sortBy(lambda x:x[1])\n",
    "result = r2.collect()\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Trailers', 1.0),\n",
       " ('Autos & Vehicles', 1.0190448285965426),\n",
       " ('News & Politics', 1.0527098256521152),\n",
       " ('Nonprofits & Activism', 1.057344064386318),\n",
       " ('Education', 1.0628976994615762),\n",
       " ('People & Blogs', 1.063884131133748),\n",
       " ('Pets & Animals', 1.0703560703560704),\n",
       " ('Howto & Style', 1.0875230863944183),\n",
       " ('Travel & Events', 1.0929411764705883),\n",
       " ('Gaming', 1.09443748882132),\n",
       " ('Sports', 1.1421507122296848),\n",
       " ('Entertainment', 1.1446024282935856),\n",
       " ('Science & Technology', 1.1626835588828102),\n",
       " ('Film & Animation', 1.1677314564158094),\n",
       " ('Comedy', 1.2142258635136394),\n",
       " ('Movies', 1.25),\n",
       " ('Music', 1.3105183216252136),\n",
       " ('Shows', 1.555045871559633)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
